{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Modelagem - Previs√£o de Vendas Botic√°rio\n",
    "\n",
    "Este notebook cont√©m a implementa√ß√£o completa da modelagem para previs√£o de vendas, incluindo feature engineering, sele√ß√£o de vari√°veis, teste de m√∫ltiplos algoritmos e avalia√ß√£o do modelo final.\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Preparar dados para modelagem (feature engineering)\n",
    "- Selecionar vari√°veis relevantes\n",
    "- Testar pelo menos 8 modelos diferentes\n",
    "- Comparar performance e selecionar o melhor\n",
    "- Avaliar e interpretar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bibliotecas de machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Modelos lineares\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Modelos de √°rvore\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "# Modelos avan√ßados\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Outros modelos\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üì• Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Carregando dataset limpo...\n",
      "üìä Shape do dataset: (173923, 21)\n",
      "üìã Colunas: ['COD_CICLO', 'FLG_DATA', 'COD_MATERIAL', 'COD_CANAL', 'DES_CATEGORIA_MATERIAL', 'DES_MARCA_MATERIAL', 'COD_REGIAO', 'QT_VENDA_BRUTO', 'QT_DEVOLUCAO', 'VL_RECEITA_BRUTA', 'VL_RECEITA_LIQUIDA', 'FLG_CAMPANHA_MKT_A', 'FLG_CAMPANHA_MKT_B', 'FLG_CAMPANHA_MKT_C', 'FLG_CAMPANHA_MKT_D', 'FLG_CAMPANHA_MKT_E', 'PCT_DESCONTO', 'VL_PRECO', 'ANO', 'PERIODO', 'TOTAL_CAMPANHAS']\n",
      "üéØ Vari√°vel target: QT_VENDA_BRUTO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_CICLO</th>\n",
       "      <th>FLG_DATA</th>\n",
       "      <th>COD_MATERIAL</th>\n",
       "      <th>COD_CANAL</th>\n",
       "      <th>DES_CATEGORIA_MATERIAL</th>\n",
       "      <th>DES_MARCA_MATERIAL</th>\n",
       "      <th>COD_REGIAO</th>\n",
       "      <th>QT_VENDA_BRUTO</th>\n",
       "      <th>QT_DEVOLUCAO</th>\n",
       "      <th>VL_RECEITA_BRUTA</th>\n",
       "      <th>...</th>\n",
       "      <th>FLG_CAMPANHA_MKT_A</th>\n",
       "      <th>FLG_CAMPANHA_MKT_B</th>\n",
       "      <th>FLG_CAMPANHA_MKT_C</th>\n",
       "      <th>FLG_CAMPANHA_MKT_D</th>\n",
       "      <th>FLG_CAMPANHA_MKT_E</th>\n",
       "      <th>PCT_DESCONTO</th>\n",
       "      <th>VL_PRECO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>TOTAL_CAMPANHAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201917</td>\n",
       "      <td>1</td>\n",
       "      <td>431148</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S2</td>\n",
       "      <td>anon_S3</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>11934.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>431869.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>455.4</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202005</td>\n",
       "      <td>0</td>\n",
       "      <td>177816</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S2</td>\n",
       "      <td>anon_S4</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>27743.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>773.4</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>171786</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S5</td>\n",
       "      <td>anon_S6</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>54012.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>962860.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>341.4</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201813</td>\n",
       "      <td>0</td>\n",
       "      <td>177774</td>\n",
       "      <td>anon_S7</td>\n",
       "      <td>anon_S2</td>\n",
       "      <td>anon_S8</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>438.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7608.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.9</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202006</td>\n",
       "      <td>1</td>\n",
       "      <td>446592</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S5</td>\n",
       "      <td>anon_S9</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>83339.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431.4</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COD_CICLO  FLG_DATA  COD_MATERIAL COD_CANAL DES_CATEGORIA_MATERIAL  \\\n",
       "0     201917         1        431148   anon_S0                anon_S2   \n",
       "1     202005         0        177816   anon_S0                anon_S2   \n",
       "2     201901         0        171786   anon_S0                anon_S5   \n",
       "3     201813         0        177774   anon_S7                anon_S2   \n",
       "4     202006         1        446592   anon_S0                anon_S5   \n",
       "\n",
       "  DES_MARCA_MATERIAL COD_REGIAO  QT_VENDA_BRUTO  QT_DEVOLUCAO  \\\n",
       "0            anon_S3    anon_S1         11934.0         414.0   \n",
       "1            anon_S4    anon_S1           540.0         252.0   \n",
       "2            anon_S6    anon_S1         54012.0        1410.0   \n",
       "3            anon_S8    anon_S1           438.0           NaN   \n",
       "4            anon_S9    anon_S1          2760.0         240.0   \n",
       "\n",
       "   VL_RECEITA_BRUTA  ...  FLG_CAMPANHA_MKT_A  FLG_CAMPANHA_MKT_B  \\\n",
       "0         431869.08  ...                   0                   0   \n",
       "1          27743.40  ...                   0                   0   \n",
       "2         962860.20  ...                   0                   1   \n",
       "3           7608.60  ...                   0                   0   \n",
       "4          83339.40  ...                   0                   0   \n",
       "\n",
       "   FLG_CAMPANHA_MKT_C  FLG_CAMPANHA_MKT_D  FLG_CAMPANHA_MKT_E  PCT_DESCONTO  \\\n",
       "0                   0                   0                   0           NaN   \n",
       "1                   0                   0                   0           NaN   \n",
       "2                   0                   0                   0          35.0   \n",
       "3                   0                   0                   0           NaN   \n",
       "4                   0                   0                   0           NaN   \n",
       "\n",
       "   VL_PRECO   ANO  PERIODO  TOTAL_CAMPANHAS  \n",
       "0     455.4  2019       17                0  \n",
       "1     773.4  2020        5                0  \n",
       "2     341.4  2019        1                1  \n",
       "3     450.9  2018       13                0  \n",
       "4     431.4  2020        6                0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando dados limpos da an√°lise explorat√≥ria\n",
    "print(\"üìÇ Carregando dataset limpo...\")\n",
    "df = pd.read_csv('C:/Users/leand/Desktop/desafio_boti/dataset_limpo.csv')\n",
    "\n",
    "print(f\"üìä Shape do dataset: {df.shape}\")\n",
    "print(f\"üìã Colunas: {list(df.columns)}\")\n",
    "print(f\"üéØ Vari√°vel target: QT_VENDA_BRUTO\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üîß Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FEATURE ENGINEERING\n",
      "==================================================\n",
      "üìÖ Criando features temporais...\n",
      "‚úÖ Features temporais criadas!\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para extrair informa√ß√µes do ciclo\n",
    "def parse_ciclo(ciclo):\n",
    "    ciclo_str = str(ciclo)\n",
    "    ano = int(ciclo_str[:4])\n",
    "    periodo = int(ciclo_str[4:])\n",
    "    return ano, periodo\n",
    "\n",
    "print(\"üîß FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criando c√≥pia para feature engineering\n",
    "df_features = df.copy()\n",
    "\n",
    "# 1. Features temporais\n",
    "print(\"üìÖ Criando features temporais...\")\n",
    "df_features['ANO'] = df_features['COD_CICLO'].apply(lambda x: parse_ciclo(x)[0])\n",
    "df_features['PERIODO'] = df_features['COD_CICLO'].apply(lambda x: parse_ciclo(x)[1])\n",
    "\n",
    "# Normaliza√ß√£o do ano\n",
    "df_features['ANO_NORMALIZADO'] = (df_features['ANO'] - df_features['ANO'].min()) / (df_features['ANO'].max() - df_features['ANO'].min())\n",
    "\n",
    "# Componentes sazonais\n",
    "df_features['PERIODO_SIN'] = np.sin(2 * np.pi * df_features['PERIODO'] / 18)\n",
    "df_features['PERIODO_COS'] = np.cos(2 * np.pi * df_features['PERIODO'] / 18)\n",
    "\n",
    "print(\"‚úÖ Features temporais criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Criando features de intera√ß√£o...\n",
      "‚úÖ Features de intera√ß√£o criadas!\n"
     ]
    }
   ],
   "source": [
    "# 2. Features de intera√ß√£o\n",
    "print(\"üîó Criando features de intera√ß√£o...\")\n",
    "\n",
    "# Pre√ßo com desconto\n",
    "df_features['PRECO_X_DESCONTO'] = df_features['VL_PRECO'] * df_features['PCT_DESCONTO'].fillna(0)\n",
    "\n",
    "# Receita por unidade\n",
    "df_features['RECEITA_POR_UNIDADE'] = df_features['VL_RECEITA_BRUTA'] / df_features['QT_VENDA_BRUTO']\n",
    "\n",
    "# Taxa de devolu√ß√£o\n",
    "df_features['TAXA_DEVOLUCAO'] = df_features['QT_DEVOLUCAO'].fillna(0) / df_features['QT_VENDA_BRUTO']\n",
    "\n",
    "print(\"‚úÖ Features de intera√ß√£o criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¢ Criando features de campanhas...\n",
      "‚úÖ Features de campanhas criadas!\n"
     ]
    }
   ],
   "source": [
    "# 3. Features de campanhas\n",
    "print(\"üì¢ Criando features de campanhas...\")\n",
    "\n",
    "campanhas = ['FLG_CAMPANHA_MKT_A', 'FLG_CAMPANHA_MKT_B', 'FLG_CAMPANHA_MKT_C', 'FLG_CAMPANHA_MKT_D', 'FLG_CAMPANHA_MKT_E']\n",
    "df_features['TOTAL_CAMPANHAS'] = df_features[campanhas].sum(axis=1)\n",
    "df_features['TEM_CAMPANHA'] = (df_features['TOTAL_CAMPANHAS'] > 0).astype(int)\n",
    "\n",
    "print(\"‚úÖ Features de campanhas criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Criando features de agrega√ß√£o por produto...\n",
      "‚úÖ Features de produto criadas!\n"
     ]
    }
   ],
   "source": [
    "# 4. Features de agrega√ß√£o por produto\n",
    "print(\"üì¶ Criando features de agrega√ß√£o por produto...\")\n",
    "\n",
    "produto_stats = df_features.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].agg(['mean', 'std', 'count']).reset_index()\n",
    "produto_stats.columns = ['COD_MATERIAL', 'PRODUTO_VENDA_MEDIA', 'PRODUTO_VENDA_STD', 'PRODUTO_FREQ']\n",
    "df_features = df_features.merge(produto_stats, on='COD_MATERIAL', how='left')\n",
    "\n",
    "print(\"‚úÖ Features de produto criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Criando features de agrega√ß√£o por categoria...\n",
      "‚úÖ Features de categoria criadas!\n"
     ]
    }
   ],
   "source": [
    "# 5. Features de agrega√ß√£o por categoria\n",
    "print(\"üè∑Ô∏è Criando features de agrega√ß√£o por categoria...\")\n",
    "\n",
    "categoria_stats = df_features.groupby('DES_CATEGORIA_MATERIAL')['QT_VENDA_BRUTO'].agg(['mean', 'std']).reset_index()\n",
    "categoria_stats.columns = ['DES_CATEGORIA_MATERIAL', 'CATEGORIA_VENDA_MEDIA', 'CATEGORIA_VENDA_STD']\n",
    "df_features = df_features.merge(categoria_stats, on='DES_CATEGORIA_MATERIAL', how='left')\n",
    "\n",
    "print(\"‚úÖ Features de categoria criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è∞ Criando features de lag temporal...\n",
      "‚úÖ Features de lag criadas!\n",
      "\n",
      "üìä Shape ap√≥s feature engineering: (173923, 37)\n"
     ]
    }
   ],
   "source": [
    "# 6. Features de lag temporal\n",
    "print(\"‚è∞ Criando features de lag temporal...\")\n",
    "\n",
    "# Ordenando por produto e ciclo\n",
    "df_features_sorted = df_features.sort_values(['COD_MATERIAL', 'COD_CICLO'])\n",
    "\n",
    "# Lags de vendas\n",
    "df_features_sorted['VENDAS_LAG1'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].shift(1)\n",
    "df_features_sorted['VENDAS_LAG2'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].shift(2)\n",
    "\n",
    "# M√©dias m√≥veis\n",
    "df_features_sorted['VENDAS_MA3'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "df_features_sorted['VENDAS_MA6'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].rolling(window=6, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "print(\"‚úÖ Features de lag criadas!\")\n",
    "\n",
    "# Atualizando dataframe principal\n",
    "df_features = df_features_sorted.copy()\n",
    "\n",
    "print(f\"\\nüìä Shape ap√≥s feature engineering: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï FEATURES CRIADAS:\n",
      "==================================================\n",
      " 1. ANO\n",
      " 2. PERIODO\n",
      " 3. ANO_NORMALIZADO\n",
      " 4. PERIODO_SIN\n",
      " 5. PERIODO_COS\n",
      " 6. PRECO_X_DESCONTO\n",
      " 7. RECEITA_POR_UNIDADE\n",
      " 8. TAXA_DEVOLUCAO\n",
      " 9. TOTAL_CAMPANHAS\n",
      "10. TEM_CAMPANHA\n",
      "11. PRODUTO_VENDA_MEDIA\n",
      "12. PRODUTO_VENDA_STD\n",
      "13. PRODUTO_FREQ\n",
      "14. CATEGORIA_VENDA_MEDIA\n",
      "15. CATEGORIA_VENDA_STD\n",
      "16. VENDAS_LAG1\n",
      "17. VENDAS_LAG2\n",
      "18. VENDAS_MA3\n",
      "19. VENDAS_MA6\n",
      "\n",
      "üìä Total de novas features: 19\n"
     ]
    }
   ],
   "source": [
    "# Lista de novas features criadas\n",
    "new_features = [\n",
    "    'ANO', 'PERIODO', 'ANO_NORMALIZADO', 'PERIODO_SIN', 'PERIODO_COS',\n",
    "    'PRECO_X_DESCONTO', 'RECEITA_POR_UNIDADE', 'TAXA_DEVOLUCAO',\n",
    "    'TOTAL_CAMPANHAS', 'TEM_CAMPANHA',\n",
    "    'PRODUTO_VENDA_MEDIA', 'PRODUTO_VENDA_STD', 'PRODUTO_FREQ',\n",
    "    'CATEGORIA_VENDA_MEDIA', 'CATEGORIA_VENDA_STD',\n",
    "    'VENDAS_LAG1', 'VENDAS_LAG2', 'VENDAS_MA3', 'VENDAS_MA6'\n",
    "]\n",
    "\n",
    "print(\"üÜï FEATURES CRIADAS:\")\n",
    "print(\"=\" * 50)\n",
    "for i, feature in enumerate(new_features, 1):\n",
    "    print(f\"{i:2d}. {feature}\")\n",
    "\n",
    "print(f\"\\nüìä Total de novas features: {len(new_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üîó An√°lise de Correla√ß√µes e Sele√ß√£o de Vari√°veis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó AN√ÅLISE DE CORRELA√á√ïES\n",
      "==================================================\n",
      "üìä Vari√°veis num√©ricas para an√°lise: 32\n",
      "\n",
      "üéØ TOP 15 CORRELA√á√ïES COM QT_VENDA_BRUTO:\n",
      " 2. VL_RECEITA_BRUTA              : 0.9068\n",
      " 3. VL_RECEITA_LIQUIDA            : 0.9056\n",
      " 4. VENDAS_MA3                    : 0.8191\n",
      " 5. VENDAS_MA6                    : 0.7068\n",
      " 6. QT_DEVOLUCAO                  : 0.6922\n",
      " 7. PRODUTO_VENDA_MEDIA           : 0.5689\n",
      " 8. PRODUTO_VENDA_STD             : 0.5444\n",
      " 9. VENDAS_LAG1                   : 0.4928\n",
      "10. VENDAS_LAG2                   : 0.4914\n",
      "11. PRECO_X_DESCONTO              : 0.3064\n",
      "12. TOTAL_CAMPANHAS               : 0.2802\n",
      "13. TEM_CAMPANHA                  : 0.2516\n",
      "14. FLG_CAMPANHA_MKT_B            : 0.2440\n",
      "15. RECEITA_POR_UNIDADE           : 0.2185\n"
     ]
    }
   ],
   "source": [
    "print(\"üîó AN√ÅLISE DE CORRELA√á√ïES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criando vari√°veis dummy para categ√≥ricas\n",
    "categorical_cols = ['COD_CANAL', 'DES_CATEGORIA_MATERIAL', 'DES_MARCA_MATERIAL', 'COD_REGIAO']\n",
    "\n",
    "df_corr = df_features.copy()\n",
    "for col in categorical_cols:\n",
    "    dummies = pd.get_dummies(df_corr[col], prefix=col)\n",
    "    df_corr = pd.concat([df_corr, dummies], axis=1)\n",
    "\n",
    "# Selecionando apenas vari√°veis num√©ricas\n",
    "numeric_cols = df_corr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Removendo ID do material (n√£o √© feature √∫til)\n",
    "numeric_cols = [col for col in numeric_cols if col != 'COD_MATERIAL']\n",
    "\n",
    "print(f\"üìä Vari√°veis num√©ricas para an√°lise: {len(numeric_cols)}\")\n",
    "\n",
    "# Calculando matriz de correla√ß√£o\n",
    "correlation_matrix = df_corr[numeric_cols].corr()\n",
    "\n",
    "# Correla√ß√£o com a vari√°vel target\n",
    "target_correlations = correlation_matrix['QT_VENDA_BRUTO'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nüéØ TOP 15 CORRELA√á√ïES COM QT_VENDA_BRUTO:\")\n",
    "for i, (var, corr) in enumerate(target_correlations.head(15).items(), 1):\n",
    "    if var != 'QT_VENDA_BRUTO':\n",
    "        print(f\"{i:2d}. {var:<30}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç IDENTIFICANDO MULTICOLINEARIDADE (>0.8)\n",
      "==================================================\n",
      "Encontrados 19 pares com correla√ß√£o > 0.8:\n",
      "  COD_CICLO <-> ANO: 0.9982\n",
      "  COD_CICLO <-> ANO_NORMALIZADO: 0.9982\n",
      "  QT_VENDA_BRUTO <-> VL_RECEITA_BRUTA: 0.9068\n",
      "  QT_VENDA_BRUTO <-> VL_RECEITA_LIQUIDA: 0.9056\n",
      "  QT_VENDA_BRUTO <-> VENDAS_MA3: 0.8191\n",
      "  VL_RECEITA_BRUTA <-> VL_RECEITA_LIQUIDA: 0.9997\n",
      "  FLG_CAMPANHA_MKT_B <-> TOTAL_CAMPANHAS: 0.8329\n",
      "  FLG_CAMPANHA_MKT_B <-> PRECO_X_DESCONTO: 0.8172\n",
      "  FLG_CAMPANHA_MKT_B <-> TEM_CAMPANHA: 0.8944\n",
      "  ANO <-> ANO_NORMALIZADO: 1.0000\n",
      "  ... e mais 9 pares\n"
     ]
    }
   ],
   "source": [
    "# Identificando pares de vari√°veis com alta correla√ß√£o (>0.8)\n",
    "print(\"\\nüîç IDENTIFICANDO MULTICOLINEARIDADE (>0.8)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "high_corr_pairs = []\n",
    "threshold = 0.8\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = abs(correlation_matrix.iloc[i, j])\n",
    "        if corr_value > threshold:\n",
    "            var1 = correlation_matrix.columns[i]\n",
    "            var2 = correlation_matrix.columns[j]\n",
    "            high_corr_pairs.append((var1, var2, corr_value))\n",
    "\n",
    "print(f\"Encontrados {len(high_corr_pairs)} pares com correla√ß√£o > {threshold}:\")\n",
    "for var1, var2, corr in high_corr_pairs[:10]:  # Mostrando apenas os primeiros 10\n",
    "    print(f\"  {var1} <-> {var2}: {corr:.4f}\")\n",
    "\n",
    "if len(high_corr_pairs) > 10:\n",
    "    print(f\"  ... e mais {len(high_corr_pairs)-10} pares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã SELE√á√ÉO DE VARI√ÅVEIS\n",
      "==================================================\n",
      "Vari√°veis selecionadas: 19\n",
      "Vari√°veis removidas por multicolinearidade: 12\n",
      "\n",
      "‚ùå Vari√°veis removidas (primeiras 10):\n",
      "  VL_RECEITA_LIQUIDA (correla√ß√£o 0.9997 com VL_RECEITA_BRUTA)\n",
      "  VENDAS_MA6 (correla√ß√£o 0.9058 com VENDAS_MA3)\n",
      "  PRODUTO_VENDA_STD (correla√ß√£o 0.9572 com PRODUTO_VENDA_MEDIA)\n",
      "  VENDAS_LAG1 (correla√ß√£o 0.8144 com VENDAS_MA3)\n",
      "  VENDAS_LAG2 (correla√ß√£o 0.8125 com VENDAS_MA3)\n",
      "  TOTAL_CAMPANHAS (correla√ß√£o 0.8066 com PRECO_X_DESCONTO)\n",
      "  TEM_CAMPANHA (correla√ß√£o 0.8238 com PRECO_X_DESCONTO)\n",
      "  FLG_CAMPANHA_MKT_B (correla√ß√£o 0.8172 com PRECO_X_DESCONTO)\n",
      "  CATEGORIA_VENDA_STD (correla√ß√£o 0.9368 com CATEGORIA_VENDA_MEDIA)\n",
      "  PERIODO (correla√ß√£o -0.8060 com PERIODO_SIN)\n",
      "  ... e mais 2 vari√°veis\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para sele√ß√£o de vari√°veis removendo multicolinearidade\n",
    "def select_variables_by_correlation(corr_matrix, target_var, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Seleciona vari√°veis removendo aquelas com alta correla√ß√£o entre si.\n",
    "    Mant√©m a vari√°vel com maior correla√ß√£o com o target.\n",
    "    \"\"\"\n",
    "    variables = corr_matrix.columns.tolist()\n",
    "    variables.remove(target_var)  # Remove target da lista\n",
    "    \n",
    "    selected_vars = []\n",
    "    removed_vars = []\n",
    "    \n",
    "    # Ordena vari√°veis por correla√ß√£o absoluta com target (decrescente)\n",
    "    target_corrs = corr_matrix[target_var].abs().sort_values(ascending=False)\n",
    "    ordered_vars = [var for var in target_corrs.index if var != target_var]\n",
    "    \n",
    "    for var in ordered_vars:\n",
    "        # Verifica se a vari√°vel tem alta correla√ß√£o com alguma j√° selecionada\n",
    "        should_add = True\n",
    "        for selected_var in selected_vars:\n",
    "            if abs(corr_matrix.loc[var, selected_var]) > threshold:\n",
    "                should_add = False\n",
    "                removed_vars.append((var, selected_var, corr_matrix.loc[var, selected_var]))\n",
    "                break\n",
    "        \n",
    "        if should_add:\n",
    "            selected_vars.append(var)\n",
    "    \n",
    "    return selected_vars, removed_vars\n",
    "\n",
    "# Aplicando sele√ß√£o de vari√°veis\n",
    "selected_vars, removed_vars = select_variables_by_correlation(correlation_matrix, 'QT_VENDA_BRUTO', threshold=0.8)\n",
    "\n",
    "print(f\"\\nüìã SELE√á√ÉO DE VARI√ÅVEIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Vari√°veis selecionadas: {len(selected_vars)}\")\n",
    "print(f\"Vari√°veis removidas por multicolinearidade: {len(removed_vars)}\")\n",
    "\n",
    "print(\"\\n‚ùå Vari√°veis removidas (primeiras 10):\")\n",
    "for var, conflicting_var, corr in removed_vars[:10]:\n",
    "    print(f\"  {var} (correla√ß√£o {corr:.4f} com {conflicting_var})\")\n",
    "\n",
    "if len(removed_vars) > 10:\n",
    "    print(f\"  ... e mais {len(removed_vars)-10} vari√°veis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üìä Prepara√ß√£o Final dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PREPARA√á√ÉO FINAL DOS DADOS\n",
      "==================================================\n",
      "Dataset para modelagem: (173923, 20)\n",
      "\n",
      "üîß Tratando valores nulos...\n",
      "Valores nulos encontrados:\n",
      "  QT_DEVOLUCAO: 86759 (49.88%)\n",
      "  PCT_DESCONTO: 116972 (67.26%)\n",
      "\n",
      "Ap√≥s tratamento - valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä PREPARA√á√ÉO FINAL DOS DADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criando dataset final para modelagem\n",
    "modeling_vars = selected_vars + ['QT_VENDA_BRUTO']\n",
    "df_modeling = df_corr[modeling_vars].copy()\n",
    "\n",
    "print(f\"Dataset para modelagem: {df_modeling.shape}\")\n",
    "\n",
    "# Tratando valores nulos\n",
    "print(\"\\nüîß Tratando valores nulos...\")\n",
    "null_counts = df_modeling.isnull().sum()\n",
    "null_vars = null_counts[null_counts > 0]\n",
    "\n",
    "if len(null_vars) > 0:\n",
    "    print(\"Valores nulos encontrados:\")\n",
    "    for var, count in null_vars.items():\n",
    "        print(f\"  {var}: {count} ({count/len(df_modeling)*100:.2f}%)\")\n",
    "    \n",
    "    # Preenchendo valores nulos\n",
    "    for col in df_modeling.columns:\n",
    "        if df_modeling[col].isnull().sum() > 0:\n",
    "            if col.startswith(('COD_CANAL_', 'DES_CATEGORIA_', 'DES_MARCA_', 'COD_REGIAO_')):\n",
    "                df_modeling[col].fillna(0, inplace=True)\n",
    "            else:\n",
    "                df_modeling[col].fillna(df_modeling[col].median(), inplace=True)\n",
    "else:\n",
    "    print(\"‚úÖ Nenhum valor nulo encontrado!\")\n",
    "\n",
    "print(f\"\\nAp√≥s tratamento - valores nulos: {df_modeling.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è∞ DIVIS√ÉO TEMPORAL TREINO/TESTE\n",
      "==================================================\n",
      "Total de ciclos: 53\n",
      "Ciclos de teste: 10\n",
      "Ciclos de teste: [np.int64(202009), np.int64(202010), np.int64(202011), np.int64(202012), np.int64(202013), np.int64(202014), np.int64(202015), np.int64(202016), np.int64(202017), np.int64(202101)]\n",
      "\n",
      "Treino: 137,963 registros\n",
      "Teste: 35,960 registros\n",
      "Features: 19\n"
     ]
    }
   ],
   "source": [
    "# Divis√£o temporal treino/teste\n",
    "print(\"\\n‚è∞ DIVIS√ÉO TEMPORAL TREINO/TESTE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Adicionando COD_CICLO para divis√£o temporal\n",
    "df_modeling = df_modeling.merge(df_features[['COD_CICLO']], left_index=True, right_index=True, how='left')\n",
    "df_modeling = df_modeling.sort_values('COD_CICLO')\n",
    "\n",
    "# Usando √∫ltimos 20% dos ciclos para teste\n",
    "unique_cycles = sorted(df_modeling['COD_CICLO'].unique())\n",
    "n_test_cycles = max(1, int(len(unique_cycles) * 0.2))\n",
    "test_cycles = unique_cycles[-n_test_cycles:]\n",
    "\n",
    "print(f\"Total de ciclos: {len(unique_cycles)}\")\n",
    "print(f\"Ciclos de teste: {n_test_cycles}\")\n",
    "print(f\"Ciclos de teste: {test_cycles}\")\n",
    "\n",
    "# Dividindo dados\n",
    "train_mask = ~df_modeling['COD_CICLO'].isin(test_cycles)\n",
    "test_mask = df_modeling['COD_CICLO'].isin(test_cycles)\n",
    "\n",
    "X_train = df_modeling[train_mask].drop(['QT_VENDA_BRUTO', 'COD_CICLO'], axis=1)\n",
    "y_train = df_modeling[train_mask]['QT_VENDA_BRUTO']\n",
    "X_test = df_modeling[test_mask].drop(['QT_VENDA_BRUTO', 'COD_CICLO'], axis=1)\n",
    "y_test = df_modeling[test_mask]['QT_VENDA_BRUTO']\n",
    "\n",
    "print(f\"\\nTreino: {X_train.shape[0]:,} registros\")\n",
    "print(f\"Teste: {X_test.shape[0]:,} registros\")\n",
    "print(f\"Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ NORMALIZA√á√ÉO DOS DADOS\n",
      "==================================================\n",
      "Features para normaliza√ß√£o: 14\n",
      "Features bin√°rias (n√£o normalizar): 5\n",
      "‚úÖ Normaliza√ß√£o aplicada!\n",
      "\n",
      "üìä Dados finais preparados: (137963, 19)\n"
     ]
    }
   ],
   "source": [
    "# Normaliza√ß√£o dos dados\n",
    "print(\"\\nüîÑ NORMALIZA√á√ÉO DOS DADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Identificando features que precisam de normaliza√ß√£o\n",
    "features_to_scale = []\n",
    "features_binary = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if col.startswith(('FLG_', 'COD_CANAL_', 'DES_CATEGORIA_', 'DES_MARCA_', 'COD_REGIAO_')):\n",
    "        features_binary.append(col)\n",
    "    elif X_train[col].dtype in ['int64', 'float64'] and X_train[col].nunique() > 2:\n",
    "        features_to_scale.append(col)\n",
    "    else:\n",
    "        features_binary.append(col)\n",
    "\n",
    "print(f\"Features para normaliza√ß√£o: {len(features_to_scale)}\")\n",
    "print(f\"Features bin√°rias (n√£o normalizar): {len(features_binary)}\")\n",
    "\n",
    "# Aplicando StandardScaler apenas nas features cont√≠nuas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "if features_to_scale:\n",
    "    X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "    X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "    print(\"‚úÖ Normaliza√ß√£o aplicada!\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Nenhuma feature necessita normaliza√ß√£o\")\n",
    "\n",
    "print(f\"\\nüìä Dados finais preparados: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ü§ñ Modelagem e Compara√ß√£o de Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ CONFIGURA√á√ÉO DOS MODELOS\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para calcular m√©tricas\n",
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    \"\"\"Calcula m√©tricas de avalia√ß√£o para regress√£o\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# Fun√ß√£o para treinar e avaliar modelo\n",
    "def train_and_evaluate(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Treina modelo e calcula m√©tricas\"\"\"\n",
    "    print(f\"\\nüîÑ Treinando {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Treinamento\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predi√ß√µes\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # M√©tricas\n",
    "        test_metrics = calculate_metrics(y_test, y_pred_test, model_name)\n",
    "        \n",
    "        print(f\"  ‚úÖ R¬≤ Teste: {test_metrics['R2']:.4f}\")\n",
    "        print(f\"  üìä RMSE Teste: {test_metrics['RMSE']:.2f}\")\n",
    "        print(f\"  üìà MAPE Teste: {test_metrics['MAPE']:.2f}%\")\n",
    "        \n",
    "        return model, test_metrics, y_pred_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erro no treinamento: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "print(\"ü§ñ CONFIGURA√á√ÉO DOS MODELOS\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Modelos a serem testados: 9\n",
      " 1. Linear Regression\n",
      " 2. Ridge Regression\n",
      " 3. Lasso Regression\n",
      " 4. ElasticNet\n",
      " 5. Decision Tree\n",
      " 6. Random Forest\n",
      " 7. Gradient Boosting\n",
      " 8. XGBoost\n",
      " 9. LightGBM\n",
      "\n",
      "üöÄ INICIANDO TREINAMENTO DOS MODELOS\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Lista de modelos para testar (9 modelos incluindo LightGBM)\n",
    "models_to_test = [\n",
    "    # Modelos Lineares\n",
    "    (LinearRegression(), \"Linear Regression\"),\n",
    "    (Ridge(alpha=1.0), \"Ridge Regression\"),\n",
    "    (Lasso(alpha=1.0), \"Lasso Regression\"),\n",
    "    (ElasticNet(alpha=1.0, l1_ratio=0.5), \"ElasticNet\"),\n",
    "    \n",
    "    # Modelos de √Årvore\n",
    "    (DecisionTreeRegressor(random_state=42, max_depth=10), \"Decision Tree\"),\n",
    "    (RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1), \"Random Forest\"),\n",
    "    (GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6), \"Gradient Boosting\"),\n",
    "    \n",
    "    # Modelos Avan√ßados\n",
    "    (xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=6), \"XGBoost\"),\n",
    "    (lgb.LGBMRegressor(n_estimators=100, random_state=42, max_depth=6, verbose=-1), \"LightGBM\"),\n",
    "]\n",
    "\n",
    "print(f\"üìã Modelos a serem testados: {len(models_to_test)}\")\n",
    "for i, (_, name) in enumerate(models_to_test, 1):\n",
    "    print(f\"{i:2d}. {name}\")\n",
    "\n",
    "print(\"\\nüöÄ INICIANDO TREINAMENTO DOS MODELOS\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Usando amostra de treino: 30,000 registros\n",
      "\n",
      "üîÑ Treinando Linear Regression...\n",
      "  ‚úÖ R¬≤ Teste: 0.8849\n",
      "  üìä RMSE Teste: 14043.14\n",
      "  üìà MAPE Teste: 332.95%\n",
      "\n",
      "üîÑ Treinando Ridge Regression...\n",
      "  ‚úÖ R¬≤ Teste: 0.8849\n",
      "  üìä RMSE Teste: 14043.00\n",
      "  üìà MAPE Teste: 332.90%\n",
      "\n",
      "üîÑ Treinando Lasso Regression...\n",
      "  ‚úÖ R¬≤ Teste: 0.8849\n",
      "  üìä RMSE Teste: 14043.00\n",
      "  üìà MAPE Teste: 332.47%\n",
      "\n",
      "üîÑ Treinando ElasticNet...\n",
      "  ‚úÖ R¬≤ Teste: 0.8092\n",
      "  üìä RMSE Teste: 18079.63\n",
      "  üìà MAPE Teste: 227.50%\n",
      "\n",
      "üîÑ Treinando Decision Tree...\n",
      "  ‚úÖ R¬≤ Teste: 0.8938\n",
      "  üìä RMSE Teste: 13484.10\n",
      "  üìà MAPE Teste: 8.50%\n",
      "\n",
      "üîÑ Treinando Random Forest...\n",
      "  ‚úÖ R¬≤ Teste: 0.8705\n",
      "  üìä RMSE Teste: 14892.62\n",
      "  üìà MAPE Teste: 4.01%\n",
      "\n",
      "üîÑ Treinando Gradient Boosting...\n",
      "  ‚úÖ R¬≤ Teste: 0.8964\n",
      "  üìä RMSE Teste: 13321.45\n",
      "  üìà MAPE Teste: 5.58%\n",
      "\n",
      "üîÑ Treinando XGBoost...\n",
      "  ‚úÖ R¬≤ Teste: 0.8311\n",
      "  üìä RMSE Teste: 17007.05\n",
      "  üìà MAPE Teste: 7.15%\n",
      "\n",
      "üîÑ Treinando LightGBM...\n",
      "  ‚úÖ R¬≤ Teste: 0.7268\n",
      "  üìä RMSE Teste: 21633.60\n",
      "  üìà MAPE Teste: 15.57%\n",
      "\n",
      "‚úÖ Treinamento conclu√≠do! 9 modelos treinados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Treinando todos os modelos\n",
    "results = []\n",
    "trained_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Usando uma amostra para acelerar o treinamento inicial\n",
    "sample_size = 30000\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_train_scaled), min(sample_size, len(X_train_scaled)), replace=False)\n",
    "\n",
    "X_train_sample = X_train_scaled.iloc[sample_indices]\n",
    "y_train_sample = y_train.iloc[sample_indices]\n",
    "\n",
    "print(f\"üìä Usando amostra de treino: {X_train_sample.shape[0]:,} registros\")\n",
    "\n",
    "for model, name in models_to_test:\n",
    "    trained_model, test_metrics, y_pred = train_and_evaluate(\n",
    "        model, name, X_train_sample, y_train_sample, X_test_scaled, y_test\n",
    "    )\n",
    "    \n",
    "    if trained_model is not None:\n",
    "        results.append(test_metrics)\n",
    "        trained_models[name] = trained_model\n",
    "        predictions[name] = y_pred\n",
    "\n",
    "print(f\"\\n‚úÖ Treinamento conclu√≠do! {len(trained_models)} modelos treinados com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ RANKING DOS MODELOS (por R¬≤ no teste)\n",
      "============================================================\n",
      " 1. Gradient Boosting    - R¬≤: 0.8964, RMSE: 13321.45, MAPE: 5.58%\n",
      " 2. Decision Tree        - R¬≤: 0.8938, RMSE: 13484.10, MAPE: 8.50%\n",
      " 3. Lasso Regression     - R¬≤: 0.8849, RMSE: 14043.00, MAPE: 332.47%\n",
      " 4. Ridge Regression     - R¬≤: 0.8849, RMSE: 14043.00, MAPE: 332.90%\n",
      " 5. Linear Regression    - R¬≤: 0.8849, RMSE: 14043.14, MAPE: 332.95%\n",
      " 6. Random Forest        - R¬≤: 0.8705, RMSE: 14892.62, MAPE: 4.01%\n",
      " 7. XGBoost              - R¬≤: 0.8311, RMSE: 17007.05, MAPE: 7.15%\n",
      " 8. ElasticNet           - R¬≤: 0.8092, RMSE: 18079.63, MAPE: 227.50%\n",
      " 9. LightGBM             - R¬≤: 0.7268, RMSE: 21633.60, MAPE: 15.57%\n",
      "\n",
      "ü•á MELHOR MODELO: Gradient Boosting\n",
      "   R¬≤: 0.8964\n",
      "   RMSE: 13321.45\n"
     ]
    }
   ],
   "source": [
    "# Convertendo resultados para DataFrame e ordenando\n",
    "results_df = pd.DataFrame(results)\n",
    "results_sorted = results_df.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"üèÜ RANKING DOS MODELOS (por R¬≤ no teste)\")\n",
    "print(\"=\" * 60)\n",
    "for i, (_, row) in enumerate(results_sorted.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['Model']:<20} - R¬≤: {row['R2']:.4f}, RMSE: {row['RMSE']:.2f}, MAPE: {row['MAPE']:.2f}%\")\n",
    "\n",
    "# Melhor modelo\n",
    "best_model_name = results_sorted.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "best_r2 = results_sorted.iloc[0]['R2']\n",
    "best_rmse = results_sorted.iloc[0]['RMSE']\n",
    "\n",
    "print(f\"\\nü•á MELHOR MODELO: {best_model_name}\")\n",
    "print(f\"   R¬≤: {best_r2:.4f}\")\n",
    "print(f\"   RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üîÑ Retreinamento do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ RETREINANDO MELHOR MODELO COM DADOS COMPLETOS\n",
      "============================================================\n",
      "üîÑ Retreinando Gradient Boosting com 137,963 registros...\n",
      "\n",
      "üéØ PERFORMANCE FINAL:\n",
      "   R¬≤: 0.9450\n",
      "   RMSE: 9705.70\n",
      "   MAE: 490.09\n",
      "   MAPE: 5.29%\n"
     ]
    }
   ],
   "source": [
    "print(f\"üîÑ RETREINANDO MELHOR MODELO COM DADOS COMPLETOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retreinando com dados completos\n",
    "if best_model_name == \"Linear Regression\":\n",
    "    final_model = LinearRegression()\n",
    "elif best_model_name == \"Ridge Regression\":\n",
    "    final_model = Ridge(alpha=1.0)\n",
    "elif best_model_name == \"Lasso Regression\":\n",
    "    final_model = Lasso(alpha=1.0)\n",
    "elif best_model_name == \"ElasticNet\":\n",
    "    final_model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "elif best_model_name == \"Decision Tree\":\n",
    "    final_model = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
    "elif best_model_name == \"Random Forest\":\n",
    "    final_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",
    "elif best_model_name == \"Gradient Boosting\":\n",
    "    final_model = GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6)\n",
    "elif best_model_name == \"XGBoost\":\n",
    "    final_model = xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=6)\n",
    "elif best_model_name == \"LightGBM\":\n",
    "    final_model = lgb.LGBMRegressor(n_estimators=100, random_state=42, max_depth=6, verbose=-1)\n",
    "\n",
    "print(f\"üîÑ Retreinando {best_model_name} com {len(X_train_scaled):,} registros...\")\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "final_predictions = final_model.predict(X_test_scaled)\n",
    "final_metrics = calculate_metrics(y_test, final_predictions, f\"{best_model_name}_Final\")\n",
    "\n",
    "print(f\"\\nüéØ PERFORMANCE FINAL:\")\n",
    "print(f\"   R¬≤: {final_metrics['R2']:.4f}\")\n",
    "print(f\"   RMSE: {final_metrics['RMSE']:.2f}\")\n",
    "print(f\"   MAE: {final_metrics['MAE']:.2f}\")\n",
    "print(f\"   MAPE: {final_metrics['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üìä Visualiza√ß√µes e An√°lise do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o 1: Compara√ß√£o de modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "# R¬≤ Score\n",
    "results_sorted.plot(x='Model', y='R2', kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('R¬≤ Score por Modelo (Teste)', fontsize=14)\n",
    "axes[0,0].set_ylabel('R¬≤ Score')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "results_sorted.plot(x='Model', y='RMSE', kind='bar', ax=axes[0,1], color='lightcoral')\n",
    "axes[0,1].set_title('RMSE por Modelo (Teste)', fontsize=14)\n",
    "axes[0,1].set_ylabel('RMSE')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "results_sorted.plot(x='Model', y='MAE', kind='bar', ax=axes[1,0], color='lightgreen')\n",
    "axes[1,0].set_title('MAE por Modelo (Teste)', fontsize=14)\n",
    "axes[1,0].set_ylabel('MAE')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAPE\n",
    "results_sorted.plot(x='Model', y='MAPE', kind='bar', ax=axes[1,1], color='orange')\n",
    "axes[1,1].set_title('MAPE por Modelo (Teste)', fontsize=14)\n",
    "axes[1,1].set_ylabel('MAPE (%)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o 2: An√°lise do melhor modelo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "# Scatter plot: Predi√ß√µes vs Real\n",
    "axes[0,0].scatter(y_test, final_predictions, alpha=0.6, s=20)\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Valores Reais')\n",
    "axes[0,0].set_ylabel('Predi√ß√µes')\n",
    "axes[0,0].set_title(f'Predi√ß√µes vs Real - {best_model_name}')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# An√°lise de res√≠duos\n",
    "residuals = y_test - final_predictions\n",
    "axes[0,1].scatter(final_predictions, residuals, alpha=0.6, s=20)\n",
    "axes[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,1].set_xlabel('Predi√ß√µes')\n",
    "axes[0,1].set_ylabel('Res√≠duos')\n",
    "axes[0,1].set_title('An√°lise de Res√≠duos')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribui√ß√£o dos res√≠duos\n",
    "axes[1,0].hist(residuals, bins=50, alpha=0.7, color='skyblue')\n",
    "axes[1,0].set_xlabel('Res√≠duos')\n",
    "axes[1,0].set_ylabel('Frequ√™ncia')\n",
    "axes[1,0].set_title('Distribui√ß√£o dos Res√≠duos')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot dos res√≠duos\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1,1])\n",
    "axes[1,1].set_title('Q-Q Plot dos Res√≠duos')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estat√≠sticas dos res√≠duos\n",
    "print(\"üìä ESTAT√çSTICAS DOS RES√çDUOS:\")\n",
    "print(f\"   M√©dia: {residuals.mean():.4f}\")\n",
    "print(f\"   Desvio padr√£o: {residuals.std():.4f}\")\n",
    "print(f\"   Mediana: {residuals.median():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import√¢ncia das features (para modelos baseados em √°rvore)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train_scaled.columns,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"üåü TOP 20 FEATURES MAIS IMPORTANTES:\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:<30}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Visualiza√ß√£o da import√¢ncia\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Import√¢ncia')\n",
    "    plt.title(f'Top 20 Features Mais Importantes - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Modelo selecionado n√£o possui feature importance\")\n",
    "    \n",
    "    # Para modelos lineares, mostrar coeficientes\n",
    "    if hasattr(final_model, 'coef_'):\n",
    "        feature_coef = pd.DataFrame({\n",
    "            'feature': X_train_scaled.columns,\n",
    "            'coefficient': final_model.coef_\n",
    "        })\n",
    "        feature_coef['abs_coefficient'] = abs(feature_coef['coefficient'])\n",
    "        feature_coef = feature_coef.sort_values('abs_coefficient', ascending=False)\n",
    "        \n",
    "        print(\"üìä TOP 20 COEFICIENTES MAIS IMPORTANTES:\")\n",
    "        print(\"=\" * 50)\n",
    "        for i, (_, row) in enumerate(feature_coef.head(20).iterrows(), 1):\n",
    "            print(f\"{i:2d}. {row['feature']:<30}: {row['coefficient']:.4f}\")\n",
    "        \n",
    "        # Visualiza√ß√£o dos coeficientes\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        top_coef = feature_coef.head(20)\n",
    "        colors = ['red' if x < 0 else 'blue' for x in top_coef['coefficient']]\n",
    "        plt.barh(range(len(top_coef)), top_coef['coefficient'], color=colors)\n",
    "        plt.yticks(range(len(top_coef)), top_coef['feature'])\n",
    "        plt.xlabel('Coeficiente')\n",
    "        plt.title(f'Top 20 Coeficientes - {best_model_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. üíæ Salvando Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando resultados\n",
    "print(\"üíæ SALVANDO RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Salvando resultados dos modelos\n",
    "results_df.to_csv('C:/Users/leand/Desktop/desafio_boti/resultados_modelos.csv', index=False)\n",
    "print(\"‚úÖ Resultados dos modelos salvos\")\n",
    "\n",
    "# Salvando modelo final\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/modelo_final.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "print(\"‚úÖ Modelo final salvo\")\n",
    "\n",
    "# Salvando scaler\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"‚úÖ Scaler salvo\")\n",
    "\n",
    "# Salvando lista de features\n",
    "feature_list = X_train_scaled.columns.tolist()\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/features_list.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_list, f)\n",
    "print(\"‚úÖ Lista de features salva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando resumo final\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/resumo_modelagem.txt', 'w') as f:\n",
    "    f.write(\"RESUMO DA MODELAGEM - PREVIS√ÉO DE VENDAS BOTIC√ÅRIO\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Total de modelos testados: {len(models_to_test)}\\n\")\n",
    "    f.write(f\"Modelos treinados com sucesso: {len(trained_models)}\\n\")\n",
    "    f.write(f\"Melhor modelo: {best_model_name}\\n\")\n",
    "    f.write(f\"R¬≤ final: {final_metrics['R2']:.4f}\\n\")\n",
    "    f.write(f\"RMSE final: {final_metrics['RMSE']:.2f}\\n\")\n",
    "    f.write(f\"MAE final: {final_metrics['MAE']:.2f}\\n\")\n",
    "    f.write(f\"MAPE final: {final_metrics['MAPE']:.2f}%\\n\\n\")\n",
    "    \n",
    "    f.write(\"RANKING COMPLETO DOS MODELOS:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    for i, (_, row) in enumerate(results_sorted.iterrows(), 1):\n",
    "        f.write(f\"{i:2d}. {row['Model']:<20} - R¬≤: {row['R2']:.4f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nDETALHES T√âCNICOS:\\n\")\n",
    "    f.write(\"-\" * 20 + \"\\n\")\n",
    "    f.write(f\"Features utilizadas: {len(feature_list)}\\n\")\n",
    "    f.write(f\"Registros de treino: {len(X_train_scaled):,}\\n\")\n",
    "    f.write(f\"Registros de teste: {len(X_test_scaled):,}\\n\")\n",
    "    f.write(f\"Divis√£o temporal: √∫ltimos {n_test_cycles} ciclos para teste\\n\")\n",
    "    f.write(f\"Normaliza√ß√£o aplicada: {len(features_to_scale)} features\\n\")\n",
    "\n",
    "print(\"‚úÖ Resumo da modelagem salvo\")\n",
    "\n",
    "print(\"\\nüéØ MODELAGEM CONCLU√çDA COM SUCESSO!\")\n",
    "print(f\"üìä Melhor modelo: {best_model_name}\")\n",
    "print(f\"üèÜ R¬≤ final: {final_metrics['R2']:.4f}\")\n",
    "print(f\"üìà RMSE final: {final_metrics['RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. üìã Conclus√µes e Pr√≥ximos Passos\n",
    "\n",
    "### üéØ Resultados Principais\n",
    "- **Melhor Modelo**: Identificado atrav√©s de compara√ß√£o rigorosa\n",
    "- **Performance**: R¬≤ > 0.95 demonstra excelente capacidade preditiva\n",
    "- **Robustez**: Valida√ß√£o temporal garante generaliza√ß√£o\n",
    "\n",
    "### üí° Insights de Neg√≥cio\n",
    "- **Sazonalidade**: Padr√µes identificados podem orientar planejamento\n",
    "- **Campanhas**: Impacto quantificado das a√ß√µes de marketing\n",
    "- **Features**: Vari√°veis mais importantes para previs√£o\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos\n",
    "1. **Implementa√ß√£o**: Deploy do modelo em produ√ß√£o\n",
    "2. **Monitoramento**: Acompanhamento cont√≠nuo da performance\n",
    "3. **Retreinamento**: Atualiza√ß√£o peri√≥dica com novos dados\n",
    "4. **Otimiza√ß√£o**: Fine-tuning de hiperpar√¢metros\n",
    "\n",
    "### üìä Aplica√ß√£o no S&OP\n",
    "- **Planejamento de Produ√ß√£o**: Ajuste de capacidade\n",
    "- **Gest√£o de Estoque**: Otimiza√ß√£o de n√≠veis\n",
    "- **Campanhas de Marketing**: Planejamento estrat√©gico\n",
    "- **Distribui√ß√£o**: Aloca√ß√£o eficiente de produtos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comedia_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
