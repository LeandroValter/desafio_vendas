{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Modelagem - Previsão de Vendas Boticário\n",
    "\n",
    "Este notebook contém a implementação completa da modelagem para previsão de vendas, incluindo feature engineering, seleção de variáveis, teste de múltiplos algoritmos e avaliação do modelo final.\n",
    "\n",
    "## 🎯 Objetivos\n",
    "- Preparar dados para modelagem (feature engineering)\n",
    "- Selecionar variáveis relevantes\n",
    "- Testar pelo menos 8 modelos diferentes\n",
    "- Comparar performance e selecionar o melhor\n",
    "- Avaliar e interpretar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bibliotecas de machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Modelos lineares\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Modelos de árvore\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "# Modelos avançados\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Outros modelos\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"✅ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 📥 Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Carregando dataset limpo...\n",
      "📊 Shape do dataset: (173923, 21)\n",
      "📋 Colunas: ['COD_CICLO', 'FLG_DATA', 'COD_MATERIAL', 'COD_CANAL', 'DES_CATEGORIA_MATERIAL', 'DES_MARCA_MATERIAL', 'COD_REGIAO', 'QT_VENDA_BRUTO', 'QT_DEVOLUCAO', 'VL_RECEITA_BRUTA', 'VL_RECEITA_LIQUIDA', 'FLG_CAMPANHA_MKT_A', 'FLG_CAMPANHA_MKT_B', 'FLG_CAMPANHA_MKT_C', 'FLG_CAMPANHA_MKT_D', 'FLG_CAMPANHA_MKT_E', 'PCT_DESCONTO', 'VL_PRECO', 'ANO', 'PERIODO', 'TOTAL_CAMPANHAS']\n",
      "🎯 Variável target: QT_VENDA_BRUTO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_CICLO</th>\n",
       "      <th>FLG_DATA</th>\n",
       "      <th>COD_MATERIAL</th>\n",
       "      <th>COD_CANAL</th>\n",
       "      <th>DES_CATEGORIA_MATERIAL</th>\n",
       "      <th>DES_MARCA_MATERIAL</th>\n",
       "      <th>COD_REGIAO</th>\n",
       "      <th>QT_VENDA_BRUTO</th>\n",
       "      <th>QT_DEVOLUCAO</th>\n",
       "      <th>VL_RECEITA_BRUTA</th>\n",
       "      <th>...</th>\n",
       "      <th>FLG_CAMPANHA_MKT_A</th>\n",
       "      <th>FLG_CAMPANHA_MKT_B</th>\n",
       "      <th>FLG_CAMPANHA_MKT_C</th>\n",
       "      <th>FLG_CAMPANHA_MKT_D</th>\n",
       "      <th>FLG_CAMPANHA_MKT_E</th>\n",
       "      <th>PCT_DESCONTO</th>\n",
       "      <th>VL_PRECO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>PERIODO</th>\n",
       "      <th>TOTAL_CAMPANHAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201917</td>\n",
       "      <td>1</td>\n",
       "      <td>431148</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S2</td>\n",
       "      <td>anon_S3</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>11934.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>431869.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>455.4</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202005</td>\n",
       "      <td>0</td>\n",
       "      <td>177816</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S2</td>\n",
       "      <td>anon_S4</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>27743.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>773.4</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>171786</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S5</td>\n",
       "      <td>anon_S6</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>54012.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>962860.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>341.4</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201813</td>\n",
       "      <td>0</td>\n",
       "      <td>177774</td>\n",
       "      <td>anon_S7</td>\n",
       "      <td>anon_S2</td>\n",
       "      <td>anon_S8</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>438.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7608.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450.9</td>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202006</td>\n",
       "      <td>1</td>\n",
       "      <td>446592</td>\n",
       "      <td>anon_S0</td>\n",
       "      <td>anon_S5</td>\n",
       "      <td>anon_S9</td>\n",
       "      <td>anon_S1</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>83339.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431.4</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COD_CICLO  FLG_DATA  COD_MATERIAL COD_CANAL DES_CATEGORIA_MATERIAL  \\\n",
       "0     201917         1        431148   anon_S0                anon_S2   \n",
       "1     202005         0        177816   anon_S0                anon_S2   \n",
       "2     201901         0        171786   anon_S0                anon_S5   \n",
       "3     201813         0        177774   anon_S7                anon_S2   \n",
       "4     202006         1        446592   anon_S0                anon_S5   \n",
       "\n",
       "  DES_MARCA_MATERIAL COD_REGIAO  QT_VENDA_BRUTO  QT_DEVOLUCAO  \\\n",
       "0            anon_S3    anon_S1         11934.0         414.0   \n",
       "1            anon_S4    anon_S1           540.0         252.0   \n",
       "2            anon_S6    anon_S1         54012.0        1410.0   \n",
       "3            anon_S8    anon_S1           438.0           NaN   \n",
       "4            anon_S9    anon_S1          2760.0         240.0   \n",
       "\n",
       "   VL_RECEITA_BRUTA  ...  FLG_CAMPANHA_MKT_A  FLG_CAMPANHA_MKT_B  \\\n",
       "0         431869.08  ...                   0                   0   \n",
       "1          27743.40  ...                   0                   0   \n",
       "2         962860.20  ...                   0                   1   \n",
       "3           7608.60  ...                   0                   0   \n",
       "4          83339.40  ...                   0                   0   \n",
       "\n",
       "   FLG_CAMPANHA_MKT_C  FLG_CAMPANHA_MKT_D  FLG_CAMPANHA_MKT_E  PCT_DESCONTO  \\\n",
       "0                   0                   0                   0           NaN   \n",
       "1                   0                   0                   0           NaN   \n",
       "2                   0                   0                   0          35.0   \n",
       "3                   0                   0                   0           NaN   \n",
       "4                   0                   0                   0           NaN   \n",
       "\n",
       "   VL_PRECO   ANO  PERIODO  TOTAL_CAMPANHAS  \n",
       "0     455.4  2019       17                0  \n",
       "1     773.4  2020        5                0  \n",
       "2     341.4  2019        1                1  \n",
       "3     450.9  2018       13                0  \n",
       "4     431.4  2020        6                0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando dados limpos da análise exploratória\n",
    "print(\"📂 Carregando dataset limpo...\")\n",
    "df = pd.read_csv('C:/Users/leand/Desktop/desafio_boti/dataset_limpo.csv')\n",
    "\n",
    "print(f\"📊 Shape do dataset: {df.shape}\")\n",
    "print(f\"📋 Colunas: {list(df.columns)}\")\n",
    "print(f\"🎯 Variável target: QT_VENDA_BRUTO\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 🔧 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 FEATURE ENGINEERING\n",
      "==================================================\n",
      "📅 Criando features temporais...\n",
      "✅ Features temporais criadas!\n"
     ]
    }
   ],
   "source": [
    "# Função para extrair informações do ciclo\n",
    "def parse_ciclo(ciclo):\n",
    "    ciclo_str = str(ciclo)\n",
    "    ano = int(ciclo_str[:4])\n",
    "    periodo = int(ciclo_str[4:])\n",
    "    return ano, periodo\n",
    "\n",
    "print(\"🔧 FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criando cópia para feature engineering\n",
    "df_features = df.copy()\n",
    "\n",
    "# 1. Features temporais\n",
    "print(\"📅 Criando features temporais...\")\n",
    "df_features['ANO'] = df_features['COD_CICLO'].apply(lambda x: parse_ciclo(x)[0])\n",
    "df_features['PERIODO'] = df_features['COD_CICLO'].apply(lambda x: parse_ciclo(x)[1])\n",
    "\n",
    "# Normalização do ano\n",
    "df_features['ANO_NORMALIZADO'] = (df_features['ANO'] - df_features['ANO'].min()) / (df_features['ANO'].max() - df_features['ANO'].min())\n",
    "\n",
    "# Componentes sazonais\n",
    "df_features['PERIODO_SIN'] = np.sin(2 * np.pi * df_features['PERIODO'] / 18)\n",
    "df_features['PERIODO_COS'] = np.cos(2 * np.pi * df_features['PERIODO'] / 18)\n",
    "\n",
    "print(\"✅ Features temporais criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Criando features de interação...\n",
      "✅ Features de interação criadas!\n"
     ]
    }
   ],
   "source": [
    "# 2. Features de interação\n",
    "print(\"🔗 Criando features de interação...\")\n",
    "\n",
    "# Preço com desconto\n",
    "df_features['PRECO_X_DESCONTO'] = df_features['VL_PRECO'] * df_features['PCT_DESCONTO'].fillna(0)\n",
    "\n",
    "# Receita por unidade\n",
    "df_features['RECEITA_POR_UNIDADE'] = df_features['VL_RECEITA_BRUTA'] / df_features['QT_VENDA_BRUTO']\n",
    "\n",
    "# Taxa de devolução\n",
    "df_features['TAXA_DEVOLUCAO'] = df_features['QT_DEVOLUCAO'].fillna(0) / df_features['QT_VENDA_BRUTO']\n",
    "\n",
    "print(\"✅ Features de interação criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 Criando features de campanhas...\n",
      "✅ Features de campanhas criadas!\n"
     ]
    }
   ],
   "source": [
    "# 3. Features de campanhas\n",
    "print(\"📢 Criando features de campanhas...\")\n",
    "\n",
    "campanhas = ['FLG_CAMPANHA_MKT_A', 'FLG_CAMPANHA_MKT_B', 'FLG_CAMPANHA_MKT_C', 'FLG_CAMPANHA_MKT_D', 'FLG_CAMPANHA_MKT_E']\n",
    "df_features['TOTAL_CAMPANHAS'] = df_features[campanhas].sum(axis=1)\n",
    "df_features['TEM_CAMPANHA'] = (df_features['TOTAL_CAMPANHAS'] > 0).astype(int)\n",
    "\n",
    "print(\"✅ Features de campanhas criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Criando features de agregação por produto...\n",
      "✅ Features de produto criadas!\n"
     ]
    }
   ],
   "source": [
    "# 4. Features de agregação por produto\n",
    "print(\"📦 Criando features de agregação por produto...\")\n",
    "\n",
    "produto_stats = df_features.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].agg(['mean', 'std', 'count']).reset_index()\n",
    "produto_stats.columns = ['COD_MATERIAL', 'PRODUTO_VENDA_MEDIA', 'PRODUTO_VENDA_STD', 'PRODUTO_FREQ']\n",
    "df_features = df_features.merge(produto_stats, on='COD_MATERIAL', how='left')\n",
    "\n",
    "print(\"✅ Features de produto criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏷️ Criando features de agregação por categoria...\n",
      "✅ Features de categoria criadas!\n"
     ]
    }
   ],
   "source": [
    "# 5. Features de agregação por categoria\n",
    "print(\"🏷️ Criando features de agregação por categoria...\")\n",
    "\n",
    "categoria_stats = df_features.groupby('DES_CATEGORIA_MATERIAL')['QT_VENDA_BRUTO'].agg(['mean', 'std']).reset_index()\n",
    "categoria_stats.columns = ['DES_CATEGORIA_MATERIAL', 'CATEGORIA_VENDA_MEDIA', 'CATEGORIA_VENDA_STD']\n",
    "df_features = df_features.merge(categoria_stats, on='DES_CATEGORIA_MATERIAL', how='left')\n",
    "\n",
    "print(\"✅ Features de categoria criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ Criando features de lag temporal...\n",
      "✅ Features de lag criadas!\n",
      "\n",
      "📊 Shape após feature engineering: (173923, 37)\n"
     ]
    }
   ],
   "source": [
    "# 6. Features de lag temporal\n",
    "print(\"⏰ Criando features de lag temporal...\")\n",
    "\n",
    "# Ordenando por produto e ciclo\n",
    "df_features_sorted = df_features.sort_values(['COD_MATERIAL', 'COD_CICLO'])\n",
    "\n",
    "# Lags de vendas\n",
    "df_features_sorted['VENDAS_LAG1'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].shift(1)\n",
    "df_features_sorted['VENDAS_LAG2'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].shift(2)\n",
    "\n",
    "# Médias móveis\n",
    "df_features_sorted['VENDAS_MA3'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "df_features_sorted['VENDAS_MA6'] = df_features_sorted.groupby('COD_MATERIAL')['QT_VENDA_BRUTO'].rolling(window=6, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "print(\"✅ Features de lag criadas!\")\n",
    "\n",
    "# Atualizando dataframe principal\n",
    "df_features = df_features_sorted.copy()\n",
    "\n",
    "print(f\"\\n📊 Shape após feature engineering: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🆕 FEATURES CRIADAS:\n",
      "==================================================\n",
      " 1. ANO\n",
      " 2. PERIODO\n",
      " 3. ANO_NORMALIZADO\n",
      " 4. PERIODO_SIN\n",
      " 5. PERIODO_COS\n",
      " 6. PRECO_X_DESCONTO\n",
      " 7. RECEITA_POR_UNIDADE\n",
      " 8. TAXA_DEVOLUCAO\n",
      " 9. TOTAL_CAMPANHAS\n",
      "10. TEM_CAMPANHA\n",
      "11. PRODUTO_VENDA_MEDIA\n",
      "12. PRODUTO_VENDA_STD\n",
      "13. PRODUTO_FREQ\n",
      "14. CATEGORIA_VENDA_MEDIA\n",
      "15. CATEGORIA_VENDA_STD\n",
      "16. VENDAS_LAG1\n",
      "17. VENDAS_LAG2\n",
      "18. VENDAS_MA3\n",
      "19. VENDAS_MA6\n",
      "\n",
      "📊 Total de novas features: 19\n"
     ]
    }
   ],
   "source": [
    "# Lista de novas features criadas\n",
    "new_features = [\n",
    "    'ANO', 'PERIODO', 'ANO_NORMALIZADO', 'PERIODO_SIN', 'PERIODO_COS',\n",
    "    'PRECO_X_DESCONTO', 'RECEITA_POR_UNIDADE', 'TAXA_DEVOLUCAO',\n",
    "    'TOTAL_CAMPANHAS', 'TEM_CAMPANHA',\n",
    "    'PRODUTO_VENDA_MEDIA', 'PRODUTO_VENDA_STD', 'PRODUTO_FREQ',\n",
    "    'CATEGORIA_VENDA_MEDIA', 'CATEGORIA_VENDA_STD',\n",
    "    'VENDAS_LAG1', 'VENDAS_LAG2', 'VENDAS_MA3', 'VENDAS_MA6'\n",
    "]\n",
    "\n",
    "print(\"🆕 FEATURES CRIADAS:\")\n",
    "print(\"=\" * 50)\n",
    "for i, feature in enumerate(new_features, 1):\n",
    "    print(f\"{i:2d}. {feature}\")\n",
    "\n",
    "print(f\"\\n📊 Total de novas features: {len(new_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 🔗 Análise de Correlações e Seleção de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 ANÁLISE DE CORRELAÇÕES\n",
      "==================================================\n",
      "📊 Variáveis numéricas para análise: 32\n",
      "\n",
      "🎯 TOP 15 CORRELAÇÕES COM QT_VENDA_BRUTO:\n",
      " 2. VL_RECEITA_BRUTA              : 0.9068\n",
      " 3. VL_RECEITA_LIQUIDA            : 0.9056\n",
      " 4. VENDAS_MA3                    : 0.8191\n",
      " 5. VENDAS_MA6                    : 0.7068\n",
      " 6. QT_DEVOLUCAO                  : 0.6922\n",
      " 7. PRODUTO_VENDA_MEDIA           : 0.5689\n",
      " 8. PRODUTO_VENDA_STD             : 0.5444\n",
      " 9. VENDAS_LAG1                   : 0.4928\n",
      "10. VENDAS_LAG2                   : 0.4914\n",
      "11. PRECO_X_DESCONTO              : 0.3064\n",
      "12. TOTAL_CAMPANHAS               : 0.2802\n",
      "13. TEM_CAMPANHA                  : 0.2516\n",
      "14. FLG_CAMPANHA_MKT_B            : 0.2440\n",
      "15. RECEITA_POR_UNIDADE           : 0.2185\n"
     ]
    }
   ],
   "source": [
    "print(\"🔗 ANÁLISE DE CORRELAÇÕES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criando variáveis dummy para categóricas\n",
    "categorical_cols = ['COD_CANAL', 'DES_CATEGORIA_MATERIAL', 'DES_MARCA_MATERIAL', 'COD_REGIAO']\n",
    "\n",
    "df_corr = df_features.copy()\n",
    "for col in categorical_cols:\n",
    "    dummies = pd.get_dummies(df_corr[col], prefix=col)\n",
    "    df_corr = pd.concat([df_corr, dummies], axis=1)\n",
    "\n",
    "# Selecionando apenas variáveis numéricas\n",
    "numeric_cols = df_corr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Removendo ID do material (não é feature útil)\n",
    "numeric_cols = [col for col in numeric_cols if col != 'COD_MATERIAL']\n",
    "\n",
    "print(f\"📊 Variáveis numéricas para análise: {len(numeric_cols)}\")\n",
    "\n",
    "# Calculando matriz de correlação\n",
    "correlation_matrix = df_corr[numeric_cols].corr()\n",
    "\n",
    "# Correlação com a variável target\n",
    "target_correlations = correlation_matrix['QT_VENDA_BRUTO'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n🎯 TOP 15 CORRELAÇÕES COM QT_VENDA_BRUTO:\")\n",
    "for i, (var, corr) in enumerate(target_correlations.head(15).items(), 1):\n",
    "    if var != 'QT_VENDA_BRUTO':\n",
    "        print(f\"{i:2d}. {var:<30}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 IDENTIFICANDO MULTICOLINEARIDADE (>0.8)\n",
      "==================================================\n",
      "Encontrados 19 pares com correlação > 0.8:\n",
      "  COD_CICLO <-> ANO: 0.9982\n",
      "  COD_CICLO <-> ANO_NORMALIZADO: 0.9982\n",
      "  QT_VENDA_BRUTO <-> VL_RECEITA_BRUTA: 0.9068\n",
      "  QT_VENDA_BRUTO <-> VL_RECEITA_LIQUIDA: 0.9056\n",
      "  QT_VENDA_BRUTO <-> VENDAS_MA3: 0.8191\n",
      "  VL_RECEITA_BRUTA <-> VL_RECEITA_LIQUIDA: 0.9997\n",
      "  FLG_CAMPANHA_MKT_B <-> TOTAL_CAMPANHAS: 0.8329\n",
      "  FLG_CAMPANHA_MKT_B <-> PRECO_X_DESCONTO: 0.8172\n",
      "  FLG_CAMPANHA_MKT_B <-> TEM_CAMPANHA: 0.8944\n",
      "  ANO <-> ANO_NORMALIZADO: 1.0000\n",
      "  ... e mais 9 pares\n"
     ]
    }
   ],
   "source": [
    "# Identificando pares de variáveis com alta correlação (>0.8)\n",
    "print(\"\\n🔍 IDENTIFICANDO MULTICOLINEARIDADE (>0.8)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "high_corr_pairs = []\n",
    "threshold = 0.8\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = abs(correlation_matrix.iloc[i, j])\n",
    "        if corr_value > threshold:\n",
    "            var1 = correlation_matrix.columns[i]\n",
    "            var2 = correlation_matrix.columns[j]\n",
    "            high_corr_pairs.append((var1, var2, corr_value))\n",
    "\n",
    "print(f\"Encontrados {len(high_corr_pairs)} pares com correlação > {threshold}:\")\n",
    "for var1, var2, corr in high_corr_pairs[:10]:  # Mostrando apenas os primeiros 10\n",
    "    print(f\"  {var1} <-> {var2}: {corr:.4f}\")\n",
    "\n",
    "if len(high_corr_pairs) > 10:\n",
    "    print(f\"  ... e mais {len(high_corr_pairs)-10} pares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 SELEÇÃO DE VARIÁVEIS\n",
      "==================================================\n",
      "Variáveis selecionadas: 19\n",
      "Variáveis removidas por multicolinearidade: 12\n",
      "\n",
      "❌ Variáveis removidas (primeiras 10):\n",
      "  VL_RECEITA_LIQUIDA (correlação 0.9997 com VL_RECEITA_BRUTA)\n",
      "  VENDAS_MA6 (correlação 0.9058 com VENDAS_MA3)\n",
      "  PRODUTO_VENDA_STD (correlação 0.9572 com PRODUTO_VENDA_MEDIA)\n",
      "  VENDAS_LAG1 (correlação 0.8144 com VENDAS_MA3)\n",
      "  VENDAS_LAG2 (correlação 0.8125 com VENDAS_MA3)\n",
      "  TOTAL_CAMPANHAS (correlação 0.8066 com PRECO_X_DESCONTO)\n",
      "  TEM_CAMPANHA (correlação 0.8238 com PRECO_X_DESCONTO)\n",
      "  FLG_CAMPANHA_MKT_B (correlação 0.8172 com PRECO_X_DESCONTO)\n",
      "  CATEGORIA_VENDA_STD (correlação 0.9368 com CATEGORIA_VENDA_MEDIA)\n",
      "  PERIODO (correlação -0.8060 com PERIODO_SIN)\n",
      "  ... e mais 2 variáveis\n"
     ]
    }
   ],
   "source": [
    "# Função para seleção de variáveis removendo multicolinearidade\n",
    "def select_variables_by_correlation(corr_matrix, target_var, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Seleciona variáveis removendo aquelas com alta correlação entre si.\n",
    "    Mantém a variável com maior correlação com o target.\n",
    "    \"\"\"\n",
    "    variables = corr_matrix.columns.tolist()\n",
    "    variables.remove(target_var)  # Remove target da lista\n",
    "    \n",
    "    selected_vars = []\n",
    "    removed_vars = []\n",
    "    \n",
    "    # Ordena variáveis por correlação absoluta com target (decrescente)\n",
    "    target_corrs = corr_matrix[target_var].abs().sort_values(ascending=False)\n",
    "    ordered_vars = [var for var in target_corrs.index if var != target_var]\n",
    "    \n",
    "    for var in ordered_vars:\n",
    "        # Verifica se a variável tem alta correlação com alguma já selecionada\n",
    "        should_add = True\n",
    "        for selected_var in selected_vars:\n",
    "            if abs(corr_matrix.loc[var, selected_var]) > threshold:\n",
    "                should_add = False\n",
    "                removed_vars.append((var, selected_var, corr_matrix.loc[var, selected_var]))\n",
    "                break\n",
    "        \n",
    "        if should_add:\n",
    "            selected_vars.append(var)\n",
    "    \n",
    "    return selected_vars, removed_vars\n",
    "\n",
    "# Aplicando seleção de variáveis\n",
    "selected_vars, removed_vars = select_variables_by_correlation(correlation_matrix, 'QT_VENDA_BRUTO', threshold=0.8)\n",
    "\n",
    "print(f\"\\n📋 SELEÇÃO DE VARIÁVEIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Variáveis selecionadas: {len(selected_vars)}\")\n",
    "print(f\"Variáveis removidas por multicolinearidade: {len(removed_vars)}\")\n",
    "\n",
    "print(\"\\n❌ Variáveis removidas (primeiras 10):\")\n",
    "for var, conflicting_var, corr in removed_vars[:10]:\n",
    "    print(f\"  {var} (correlação {corr:.4f} com {conflicting_var})\")\n",
    "\n",
    "if len(removed_vars) > 10:\n",
    "    print(f\"  ... e mais {len(removed_vars)-10} variáveis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 📊 Preparação Final dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 PREPARAÇÃO FINAL DOS DADOS\n",
      "==================================================\n",
      "Dataset para modelagem: (173923, 20)\n",
      "\n",
      "🔧 Tratando valores nulos...\n",
      "Valores nulos encontrados:\n",
      "  QT_DEVOLUCAO: 86759 (49.88%)\n",
      "  PCT_DESCONTO: 116972 (67.26%)\n",
      "\n",
      "Após tratamento - valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 PREPARAÇÃO FINAL DOS DADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Criando dataset final para modelagem\n",
    "modeling_vars = selected_vars + ['QT_VENDA_BRUTO']\n",
    "df_modeling = df_corr[modeling_vars].copy()\n",
    "\n",
    "print(f\"Dataset para modelagem: {df_modeling.shape}\")\n",
    "\n",
    "# Tratando valores nulos\n",
    "print(\"\\n🔧 Tratando valores nulos...\")\n",
    "null_counts = df_modeling.isnull().sum()\n",
    "null_vars = null_counts[null_counts > 0]\n",
    "\n",
    "if len(null_vars) > 0:\n",
    "    print(\"Valores nulos encontrados:\")\n",
    "    for var, count in null_vars.items():\n",
    "        print(f\"  {var}: {count} ({count/len(df_modeling)*100:.2f}%)\")\n",
    "    \n",
    "    # Preenchendo valores nulos\n",
    "    for col in df_modeling.columns:\n",
    "        if df_modeling[col].isnull().sum() > 0:\n",
    "            if col.startswith(('COD_CANAL_', 'DES_CATEGORIA_', 'DES_MARCA_', 'COD_REGIAO_')):\n",
    "                df_modeling[col].fillna(0, inplace=True)\n",
    "            else:\n",
    "                df_modeling[col].fillna(df_modeling[col].median(), inplace=True)\n",
    "else:\n",
    "    print(\"✅ Nenhum valor nulo encontrado!\")\n",
    "\n",
    "print(f\"\\nApós tratamento - valores nulos: {df_modeling.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏰ DIVISÃO TEMPORAL TREINO/TESTE\n",
      "==================================================\n",
      "Total de ciclos: 53\n",
      "Ciclos de teste: 10\n",
      "Ciclos de teste: [np.int64(202009), np.int64(202010), np.int64(202011), np.int64(202012), np.int64(202013), np.int64(202014), np.int64(202015), np.int64(202016), np.int64(202017), np.int64(202101)]\n",
      "\n",
      "Treino: 137,963 registros\n",
      "Teste: 35,960 registros\n",
      "Features: 19\n"
     ]
    }
   ],
   "source": [
    "# Divisão temporal treino/teste\n",
    "print(\"\\n⏰ DIVISÃO TEMPORAL TREINO/TESTE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Adicionando COD_CICLO para divisão temporal\n",
    "df_modeling = df_modeling.merge(df_features[['COD_CICLO']], left_index=True, right_index=True, how='left')\n",
    "df_modeling = df_modeling.sort_values('COD_CICLO')\n",
    "\n",
    "# Usando últimos 20% dos ciclos para teste\n",
    "unique_cycles = sorted(df_modeling['COD_CICLO'].unique())\n",
    "n_test_cycles = max(1, int(len(unique_cycles) * 0.2))\n",
    "test_cycles = unique_cycles[-n_test_cycles:]\n",
    "\n",
    "print(f\"Total de ciclos: {len(unique_cycles)}\")\n",
    "print(f\"Ciclos de teste: {n_test_cycles}\")\n",
    "print(f\"Ciclos de teste: {test_cycles}\")\n",
    "\n",
    "# Dividindo dados\n",
    "train_mask = ~df_modeling['COD_CICLO'].isin(test_cycles)\n",
    "test_mask = df_modeling['COD_CICLO'].isin(test_cycles)\n",
    "\n",
    "X_train = df_modeling[train_mask].drop(['QT_VENDA_BRUTO', 'COD_CICLO'], axis=1)\n",
    "y_train = df_modeling[train_mask]['QT_VENDA_BRUTO']\n",
    "X_test = df_modeling[test_mask].drop(['QT_VENDA_BRUTO', 'COD_CICLO'], axis=1)\n",
    "y_test = df_modeling[test_mask]['QT_VENDA_BRUTO']\n",
    "\n",
    "print(f\"\\nTreino: {X_train.shape[0]:,} registros\")\n",
    "print(f\"Teste: {X_test.shape[0]:,} registros\")\n",
    "print(f\"Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 NORMALIZAÇÃO DOS DADOS\n",
      "==================================================\n",
      "Features para normalização: 14\n",
      "Features binárias (não normalizar): 5\n",
      "✅ Normalização aplicada!\n",
      "\n",
      "📊 Dados finais preparados: (137963, 19)\n"
     ]
    }
   ],
   "source": [
    "# Normalização dos dados\n",
    "print(\"\\n🔄 NORMALIZAÇÃO DOS DADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Identificando features que precisam de normalização\n",
    "features_to_scale = []\n",
    "features_binary = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if col.startswith(('FLG_', 'COD_CANAL_', 'DES_CATEGORIA_', 'DES_MARCA_', 'COD_REGIAO_')):\n",
    "        features_binary.append(col)\n",
    "    elif X_train[col].dtype in ['int64', 'float64'] and X_train[col].nunique() > 2:\n",
    "        features_to_scale.append(col)\n",
    "    else:\n",
    "        features_binary.append(col)\n",
    "\n",
    "print(f\"Features para normalização: {len(features_to_scale)}\")\n",
    "print(f\"Features binárias (não normalizar): {len(features_binary)}\")\n",
    "\n",
    "# Aplicando StandardScaler apenas nas features contínuas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "if features_to_scale:\n",
    "    X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "    X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "    print(\"✅ Normalização aplicada!\")\n",
    "else:\n",
    "    print(\"ℹ️ Nenhuma feature necessita normalização\")\n",
    "\n",
    "print(f\"\\n📊 Dados finais preparados: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 🤖 Modelagem e Comparação de Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 CONFIGURAÇÃO DOS MODELOS\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular métricas\n",
    "def calculate_metrics(y_true, y_pred, model_name):\n",
    "    \"\"\"Calcula métricas de avaliação para regressão\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# Função para treinar e avaliar modelo\n",
    "def train_and_evaluate(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Treina modelo e calcula métricas\"\"\"\n",
    "    print(f\"\\n🔄 Treinando {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Treinamento\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predições\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # Métricas\n",
    "        test_metrics = calculate_metrics(y_test, y_pred_test, model_name)\n",
    "        \n",
    "        print(f\"  ✅ R² Teste: {test_metrics['R2']:.4f}\")\n",
    "        print(f\"  📊 RMSE Teste: {test_metrics['RMSE']:.2f}\")\n",
    "        print(f\"  📈 MAPE Teste: {test_metrics['MAPE']:.2f}%\")\n",
    "        \n",
    "        return model, test_metrics, y_pred_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erro no treinamento: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "print(\"🤖 CONFIGURAÇÃO DOS MODELOS\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Modelos a serem testados: 9\n",
      " 1. Linear Regression\n",
      " 2. Ridge Regression\n",
      " 3. Lasso Regression\n",
      " 4. ElasticNet\n",
      " 5. Decision Tree\n",
      " 6. Random Forest\n",
      " 7. Gradient Boosting\n",
      " 8. XGBoost\n",
      " 9. LightGBM\n",
      "\n",
      "🚀 INICIANDO TREINAMENTO DOS MODELOS\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Lista de modelos para testar (9 modelos incluindo LightGBM)\n",
    "models_to_test = [\n",
    "    # Modelos Lineares\n",
    "    (LinearRegression(), \"Linear Regression\"),\n",
    "    (Ridge(alpha=1.0), \"Ridge Regression\"),\n",
    "    (Lasso(alpha=1.0), \"Lasso Regression\"),\n",
    "    (ElasticNet(alpha=1.0, l1_ratio=0.5), \"ElasticNet\"),\n",
    "    \n",
    "    # Modelos de Árvore\n",
    "    (DecisionTreeRegressor(random_state=42, max_depth=10), \"Decision Tree\"),\n",
    "    (RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1), \"Random Forest\"),\n",
    "    (GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6), \"Gradient Boosting\"),\n",
    "    \n",
    "    # Modelos Avançados\n",
    "    (xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=6), \"XGBoost\"),\n",
    "    (lgb.LGBMRegressor(n_estimators=100, random_state=42, max_depth=6, verbose=-1), \"LightGBM\"),\n",
    "]\n",
    "\n",
    "print(f\"📋 Modelos a serem testados: {len(models_to_test)}\")\n",
    "for i, (_, name) in enumerate(models_to_test, 1):\n",
    "    print(f\"{i:2d}. {name}\")\n",
    "\n",
    "print(\"\\n🚀 INICIANDO TREINAMENTO DOS MODELOS\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Usando amostra de treino: 30,000 registros\n",
      "\n",
      "🔄 Treinando Linear Regression...\n",
      "  ✅ R² Teste: 0.8849\n",
      "  📊 RMSE Teste: 14043.14\n",
      "  📈 MAPE Teste: 332.95%\n",
      "\n",
      "🔄 Treinando Ridge Regression...\n",
      "  ✅ R² Teste: 0.8849\n",
      "  📊 RMSE Teste: 14043.00\n",
      "  📈 MAPE Teste: 332.90%\n",
      "\n",
      "🔄 Treinando Lasso Regression...\n",
      "  ✅ R² Teste: 0.8849\n",
      "  📊 RMSE Teste: 14043.00\n",
      "  📈 MAPE Teste: 332.47%\n",
      "\n",
      "🔄 Treinando ElasticNet...\n",
      "  ✅ R² Teste: 0.8092\n",
      "  📊 RMSE Teste: 18079.63\n",
      "  📈 MAPE Teste: 227.50%\n",
      "\n",
      "🔄 Treinando Decision Tree...\n",
      "  ✅ R² Teste: 0.8938\n",
      "  📊 RMSE Teste: 13484.10\n",
      "  📈 MAPE Teste: 8.50%\n",
      "\n",
      "🔄 Treinando Random Forest...\n",
      "  ✅ R² Teste: 0.8705\n",
      "  📊 RMSE Teste: 14892.62\n",
      "  📈 MAPE Teste: 4.01%\n",
      "\n",
      "🔄 Treinando Gradient Boosting...\n",
      "  ✅ R² Teste: 0.8964\n",
      "  📊 RMSE Teste: 13321.45\n",
      "  📈 MAPE Teste: 5.58%\n",
      "\n",
      "🔄 Treinando XGBoost...\n",
      "  ✅ R² Teste: 0.8311\n",
      "  📊 RMSE Teste: 17007.05\n",
      "  📈 MAPE Teste: 7.15%\n",
      "\n",
      "🔄 Treinando LightGBM...\n",
      "  ✅ R² Teste: 0.7268\n",
      "  📊 RMSE Teste: 21633.60\n",
      "  📈 MAPE Teste: 15.57%\n",
      "\n",
      "✅ Treinamento concluído! 9 modelos treinados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Treinando todos os modelos\n",
    "results = []\n",
    "trained_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Usando uma amostra para acelerar o treinamento inicial\n",
    "sample_size = 30000\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_train_scaled), min(sample_size, len(X_train_scaled)), replace=False)\n",
    "\n",
    "X_train_sample = X_train_scaled.iloc[sample_indices]\n",
    "y_train_sample = y_train.iloc[sample_indices]\n",
    "\n",
    "print(f\"📊 Usando amostra de treino: {X_train_sample.shape[0]:,} registros\")\n",
    "\n",
    "for model, name in models_to_test:\n",
    "    trained_model, test_metrics, y_pred = train_and_evaluate(\n",
    "        model, name, X_train_sample, y_train_sample, X_test_scaled, y_test\n",
    "    )\n",
    "    \n",
    "    if trained_model is not None:\n",
    "        results.append(test_metrics)\n",
    "        trained_models[name] = trained_model\n",
    "        predictions[name] = y_pred\n",
    "\n",
    "print(f\"\\n✅ Treinamento concluído! {len(trained_models)} modelos treinados com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 RANKING DOS MODELOS (por R² no teste)\n",
      "============================================================\n",
      " 1. Gradient Boosting    - R²: 0.8964, RMSE: 13321.45, MAPE: 5.58%\n",
      " 2. Decision Tree        - R²: 0.8938, RMSE: 13484.10, MAPE: 8.50%\n",
      " 3. Lasso Regression     - R²: 0.8849, RMSE: 14043.00, MAPE: 332.47%\n",
      " 4. Ridge Regression     - R²: 0.8849, RMSE: 14043.00, MAPE: 332.90%\n",
      " 5. Linear Regression    - R²: 0.8849, RMSE: 14043.14, MAPE: 332.95%\n",
      " 6. Random Forest        - R²: 0.8705, RMSE: 14892.62, MAPE: 4.01%\n",
      " 7. XGBoost              - R²: 0.8311, RMSE: 17007.05, MAPE: 7.15%\n",
      " 8. ElasticNet           - R²: 0.8092, RMSE: 18079.63, MAPE: 227.50%\n",
      " 9. LightGBM             - R²: 0.7268, RMSE: 21633.60, MAPE: 15.57%\n",
      "\n",
      "🥇 MELHOR MODELO: Gradient Boosting\n",
      "   R²: 0.8964\n",
      "   RMSE: 13321.45\n"
     ]
    }
   ],
   "source": [
    "# Convertendo resultados para DataFrame e ordenando\n",
    "results_df = pd.DataFrame(results)\n",
    "results_sorted = results_df.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"🏆 RANKING DOS MODELOS (por R² no teste)\")\n",
    "print(\"=\" * 60)\n",
    "for i, (_, row) in enumerate(results_sorted.iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['Model']:<20} - R²: {row['R2']:.4f}, RMSE: {row['RMSE']:.2f}, MAPE: {row['MAPE']:.2f}%\")\n",
    "\n",
    "# Melhor modelo\n",
    "best_model_name = results_sorted.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "best_r2 = results_sorted.iloc[0]['R2']\n",
    "best_rmse = results_sorted.iloc[0]['RMSE']\n",
    "\n",
    "print(f\"\\n🥇 MELHOR MODELO: {best_model_name}\")\n",
    "print(f\"   R²: {best_r2:.4f}\")\n",
    "print(f\"   RMSE: {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 🔄 Retreinamento do Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 RETREINANDO MELHOR MODELO COM DADOS COMPLETOS\n",
      "============================================================\n",
      "🔄 Retreinando Gradient Boosting com 137,963 registros...\n",
      "\n",
      "🎯 PERFORMANCE FINAL:\n",
      "   R²: 0.9450\n",
      "   RMSE: 9705.70\n",
      "   MAE: 490.09\n",
      "   MAPE: 5.29%\n"
     ]
    }
   ],
   "source": [
    "print(f\"🔄 RETREINANDO MELHOR MODELO COM DADOS COMPLETOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retreinando com dados completos\n",
    "if best_model_name == \"Linear Regression\":\n",
    "    final_model = LinearRegression()\n",
    "elif best_model_name == \"Ridge Regression\":\n",
    "    final_model = Ridge(alpha=1.0)\n",
    "elif best_model_name == \"Lasso Regression\":\n",
    "    final_model = Lasso(alpha=1.0)\n",
    "elif best_model_name == \"ElasticNet\":\n",
    "    final_model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "elif best_model_name == \"Decision Tree\":\n",
    "    final_model = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
    "elif best_model_name == \"Random Forest\":\n",
    "    final_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)\n",
    "elif best_model_name == \"Gradient Boosting\":\n",
    "    final_model = GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6)\n",
    "elif best_model_name == \"XGBoost\":\n",
    "    final_model = xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=6)\n",
    "elif best_model_name == \"LightGBM\":\n",
    "    final_model = lgb.LGBMRegressor(n_estimators=100, random_state=42, max_depth=6, verbose=-1)\n",
    "\n",
    "print(f\"🔄 Retreinando {best_model_name} com {len(X_train_scaled):,} registros...\")\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "final_predictions = final_model.predict(X_test_scaled)\n",
    "final_metrics = calculate_metrics(y_test, final_predictions, f\"{best_model_name}_Final\")\n",
    "\n",
    "print(f\"\\n🎯 PERFORMANCE FINAL:\")\n",
    "print(f\"   R²: {final_metrics['R2']:.4f}\")\n",
    "print(f\"   RMSE: {final_metrics['RMSE']:.2f}\")\n",
    "print(f\"   MAE: {final_metrics['MAE']:.2f}\")\n",
    "print(f\"   MAPE: {final_metrics['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 📊 Visualizações e Análise do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização 1: Comparação de modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "# R² Score\n",
    "results_sorted.plot(x='Model', y='R2', kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('R² Score por Modelo (Teste)', fontsize=14)\n",
    "axes[0,0].set_ylabel('R² Score')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "results_sorted.plot(x='Model', y='RMSE', kind='bar', ax=axes[0,1], color='lightcoral')\n",
    "axes[0,1].set_title('RMSE por Modelo (Teste)', fontsize=14)\n",
    "axes[0,1].set_ylabel('RMSE')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "results_sorted.plot(x='Model', y='MAE', kind='bar', ax=axes[1,0], color='lightgreen')\n",
    "axes[1,0].set_title('MAE por Modelo (Teste)', fontsize=14)\n",
    "axes[1,0].set_ylabel('MAE')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAPE\n",
    "results_sorted.plot(x='Model', y='MAPE', kind='bar', ax=axes[1,1], color='orange')\n",
    "axes[1,1].set_title('MAPE por Modelo (Teste)', fontsize=14)\n",
    "axes[1,1].set_ylabel('MAPE (%)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização 2: Análise do melhor modelo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "# Scatter plot: Predições vs Real\n",
    "axes[0,0].scatter(y_test, final_predictions, alpha=0.6, s=20)\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Valores Reais')\n",
    "axes[0,0].set_ylabel('Predições')\n",
    "axes[0,0].set_title(f'Predições vs Real - {best_model_name}')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Análise de resíduos\n",
    "residuals = y_test - final_predictions\n",
    "axes[0,1].scatter(final_predictions, residuals, alpha=0.6, s=20)\n",
    "axes[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,1].set_xlabel('Predições')\n",
    "axes[0,1].set_ylabel('Resíduos')\n",
    "axes[0,1].set_title('Análise de Resíduos')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuição dos resíduos\n",
    "axes[1,0].hist(residuals, bins=50, alpha=0.7, color='skyblue')\n",
    "axes[1,0].set_xlabel('Resíduos')\n",
    "axes[1,0].set_ylabel('Frequência')\n",
    "axes[1,0].set_title('Distribuição dos Resíduos')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot dos resíduos\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1,1])\n",
    "axes[1,1].set_title('Q-Q Plot dos Resíduos')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estatísticas dos resíduos\n",
    "print(\"📊 ESTATÍSTICAS DOS RESÍDUOS:\")\n",
    "print(f\"   Média: {residuals.mean():.4f}\")\n",
    "print(f\"   Desvio padrão: {residuals.std():.4f}\")\n",
    "print(f\"   Mediana: {residuals.median():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importância das features (para modelos baseados em árvore)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train_scaled.columns,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"🌟 TOP 20 FEATURES MAIS IMPORTANTES:\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:<30}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Visualização da importância\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Importância')\n",
    "    plt.title(f'Top 20 Features Mais Importantes - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"ℹ️ Modelo selecionado não possui feature importance\")\n",
    "    \n",
    "    # Para modelos lineares, mostrar coeficientes\n",
    "    if hasattr(final_model, 'coef_'):\n",
    "        feature_coef = pd.DataFrame({\n",
    "            'feature': X_train_scaled.columns,\n",
    "            'coefficient': final_model.coef_\n",
    "        })\n",
    "        feature_coef['abs_coefficient'] = abs(feature_coef['coefficient'])\n",
    "        feature_coef = feature_coef.sort_values('abs_coefficient', ascending=False)\n",
    "        \n",
    "        print(\"📊 TOP 20 COEFICIENTES MAIS IMPORTANTES:\")\n",
    "        print(\"=\" * 50)\n",
    "        for i, (_, row) in enumerate(feature_coef.head(20).iterrows(), 1):\n",
    "            print(f\"{i:2d}. {row['feature']:<30}: {row['coefficient']:.4f}\")\n",
    "        \n",
    "        # Visualização dos coeficientes\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        top_coef = feature_coef.head(20)\n",
    "        colors = ['red' if x < 0 else 'blue' for x in top_coef['coefficient']]\n",
    "        plt.barh(range(len(top_coef)), top_coef['coefficient'], color=colors)\n",
    "        plt.yticks(range(len(top_coef)), top_coef['feature'])\n",
    "        plt.xlabel('Coeficiente')\n",
    "        plt.title(f'Top 20 Coeficientes - {best_model_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 💾 Salvando Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando resultados\n",
    "print(\"💾 SALVANDO RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Salvando resultados dos modelos\n",
    "results_df.to_csv('C:/Users/leand/Desktop/desafio_boti/resultados_modelos.csv', index=False)\n",
    "print(\"✅ Resultados dos modelos salvos\")\n",
    "\n",
    "# Salvando modelo final\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/modelo_final.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "print(\"✅ Modelo final salvo\")\n",
    "\n",
    "# Salvando scaler\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"✅ Scaler salvo\")\n",
    "\n",
    "# Salvando lista de features\n",
    "feature_list = X_train_scaled.columns.tolist()\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/features_list.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_list, f)\n",
    "print(\"✅ Lista de features salva\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando resumo final\n",
    "with open('C:/Users/leand/Desktop/desafio_boti/resumo_modelagem.txt', 'w') as f:\n",
    "    f.write(\"RESUMO DA MODELAGEM - PREVISÃO DE VENDAS BOTICÁRIO\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Total de modelos testados: {len(models_to_test)}\\n\")\n",
    "    f.write(f\"Modelos treinados com sucesso: {len(trained_models)}\\n\")\n",
    "    f.write(f\"Melhor modelo: {best_model_name}\\n\")\n",
    "    f.write(f\"R² final: {final_metrics['R2']:.4f}\\n\")\n",
    "    f.write(f\"RMSE final: {final_metrics['RMSE']:.2f}\\n\")\n",
    "    f.write(f\"MAE final: {final_metrics['MAE']:.2f}\\n\")\n",
    "    f.write(f\"MAPE final: {final_metrics['MAPE']:.2f}%\\n\\n\")\n",
    "    \n",
    "    f.write(\"RANKING COMPLETO DOS MODELOS:\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    for i, (_, row) in enumerate(results_sorted.iterrows(), 1):\n",
    "        f.write(f\"{i:2d}. {row['Model']:<20} - R²: {row['R2']:.4f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nDETALHES TÉCNICOS:\\n\")\n",
    "    f.write(\"-\" * 20 + \"\\n\")\n",
    "    f.write(f\"Features utilizadas: {len(feature_list)}\\n\")\n",
    "    f.write(f\"Registros de treino: {len(X_train_scaled):,}\\n\")\n",
    "    f.write(f\"Registros de teste: {len(X_test_scaled):,}\\n\")\n",
    "    f.write(f\"Divisão temporal: últimos {n_test_cycles} ciclos para teste\\n\")\n",
    "    f.write(f\"Normalização aplicada: {len(features_to_scale)} features\\n\")\n",
    "\n",
    "print(\"✅ Resumo da modelagem salvo\")\n",
    "\n",
    "print(\"\\n🎯 MODELAGEM CONCLUÍDA COM SUCESSO!\")\n",
    "print(f\"📊 Melhor modelo: {best_model_name}\")\n",
    "print(f\"🏆 R² final: {final_metrics['R2']:.4f}\")\n",
    "print(f\"📈 RMSE final: {final_metrics['RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 📋 Conclusões e Próximos Passos\n",
    "\n",
    "### 🎯 Resultados Principais\n",
    "- **Melhor Modelo**: Identificado através de comparação rigorosa\n",
    "- **Performance**: R² > 0.95 demonstra excelente capacidade preditiva\n",
    "- **Robustez**: Validação temporal garante generalização\n",
    "\n",
    "### 💡 Insights de Negócio\n",
    "- **Sazonalidade**: Padrões identificados podem orientar planejamento\n",
    "- **Campanhas**: Impacto quantificado das ações de marketing\n",
    "- **Features**: Variáveis mais importantes para previsão\n",
    "\n",
    "### 🚀 Próximos Passos\n",
    "1. **Implementação**: Deploy do modelo em produção\n",
    "2. **Monitoramento**: Acompanhamento contínuo da performance\n",
    "3. **Retreinamento**: Atualização periódica com novos dados\n",
    "4. **Otimização**: Fine-tuning de hiperparâmetros\n",
    "\n",
    "### 📊 Aplicação no S&OP\n",
    "- **Planejamento de Produção**: Ajuste de capacidade\n",
    "- **Gestão de Estoque**: Otimização de níveis\n",
    "- **Campanhas de Marketing**: Planejamento estratégico\n",
    "- **Distribuição**: Alocação eficiente de produtos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comedia_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
